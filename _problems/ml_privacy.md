---
title: "ML Privacy"
description: "Robust Verification and privacy"
problem_statement: 
contribution: 
---

<!-- Learning in federated setups enables more control over their data for users. Despite this advantage, it is difficult to ensure that the privacy of users is preserved with strong guarantees while learning something useful from the users' data. In this line of works, we focus on the question if there exist algorithms that show a good trade-off between utility and privacy. We show several key technical contributions that build on top of the principled framework of **differential privacy** to answer positively. -->