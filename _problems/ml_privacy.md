---
layout: page
title: "Robust Verification and privacy"
weight: 4
tag: "privacy"
after-content: publications-rel.html
---

There are more examples of principled approaches to analyzing machine learning
security in our work. We applied quantitative verification for fairness and adversarial robustness for
neural networks [5, 6]. We have analyzed when membership inference tests are conclusive. Our work
shows the importance of causal reasoning here, as opposed to drawing conclusions purely with observations of statistical correlation [7]. We have worked on making differential privacy more practical for
fully-distributed graph processing, e.g. for hierarchical clustering [8] and training GNNs [9]. Lastly, we
are studying data repudiation, i.e., convincing a verifier that a data point was not used in training [10].